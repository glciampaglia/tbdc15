{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import tarfile\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers[0].setFormatter(logging.Formatter('%(asctime)s: %(message)s'))\n",
    "\n",
    "locations = {\n",
    "    'gfs': '/l/cnets/datasets/Telecom_BDC_2015',\n",
    "    'diskstation': '/media/diskstation/Datasets/Telecom Big Data Challenge 2015',\n",
    "    'data': os.path.expanduser('~/data/tbdc15'),\n",
    "    'hdd': '/media/giovanni/Multimedia/Datasets/Telecom Big Data Challenge 2015',\n",
    "    'repo': os.path.expanduser('~/repos/tbdc15')\n",
    "}\n",
    "\n",
    "\n",
    "def getpaths(city, loc='gfs', boxesloc=None, storeloc=None):\n",
    "    root = locations[loc]\n",
    "    city_codes = {'RO': 'RM'}\n",
    "    code = city[:2].upper()\n",
    "    if code in city_codes:\n",
    "        code = city_codes[code]\n",
    "    paths = {\n",
    "        'trips': '{root}/infoblu/{city}.tar.gz'.format(root=root, city=city),\n",
    "        'accidents': '{root}/unipol/BDC2015_UnipolsaiClaims2014_{city}.csv'.format(root=root, city=code),\n",
    "        'boxes': '{root}/city_boxes.csv'.format(root=root if boxesloc is None else locations[boxesloc]),\n",
    "        'store': '{root}/trip_accidents_store.hdf'.format(root=root if storeloc is None else locations[storeloc])\n",
    "    }\n",
    "    return paths\n",
    "\n",
    "\n",
    "def getbox(path, city):\n",
    "    city_code = city[0].lower()\n",
    "    df_box = pandas.read_csv(path, index_col='city')\n",
    "    df_box.ix[city_code]\n",
    "    box = df_box.ix[city_code].to_dict()\n",
    "    return box\n",
    "\n",
    "\n",
    "def read_trips(path, box, scale=1000.0, break_at=None):\n",
    "    index_columns = ['i', 'j', 'weekday', 'hour']\n",
    "    trips = pandas.DataFrame(columns=index_columns + ['trips', 'trips_start']).set_index(index_columns)\n",
    "\n",
    "    # set break_at to an integer and it will stop exactly after that number of iterations\n",
    "    i = 0\n",
    "\n",
    "    with tarfile.open(path, mode='r:gz') as tf:\n",
    "        # open tar file in random access mode with on-the-fly gzip decompression\n",
    "        for member in tf:\n",
    "            if break_at is not None and i == break_at:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "            # read contents of TAR archive. Each file in the archive contains \n",
    "            # the data of a different day.\n",
    "            logger.info(member.name)\n",
    "            f = tf.extractfile(member)\n",
    "\n",
    "            # do not use the \"type\" and \"speed\" columns, since we don't need them. This saves memory.\n",
    "            df = pandas.read_csv(f, \n",
    "                                 names=['trip', 'timestamp', 'lat', 'lon', 'type', 'speed'],\n",
    "                                 usecols=['trip', 'timestamp', 'lat', 'lon'],\n",
    "                                 sep=';', \n",
    "                                 parse_dates=['timestamp'])\n",
    "\n",
    "            # compute the cell, weekday, and hour\n",
    "            df['i'] = ((df['lat'] - box['lat_min']) * scale).round()\n",
    "            df['j'] = ((df['lon'] - box['lon_min']) * scale).round()\n",
    "            df['weekday'] = df['timestamp'].map(pandas.Timestamp.weekday)\n",
    "            df['hour'] = df['timestamp'].map(lambda k: k.hour)\n",
    "\n",
    "            # count how many trips in each cell, weekday, hour and append. \n",
    "            # Note that the first group-by returns a series object, \n",
    "            # and we wrap this into a DataFrame.        \n",
    "            s1 = df.filter(index_columns).groupby(index_columns).apply(len)\n",
    "\n",
    "            # do the same but only considering the first frame of each trip.\n",
    "            df_ff = df.groupby('trip', as_index=False).head(1)\n",
    "            s2 = df_ff.filter(index_columns).groupby(index_columns).apply(len)\n",
    "\n",
    "            df = pandas.DataFrame({'trips': s1, 'trips_start': s2})\n",
    "            \n",
    "            trips = trips.append(df)\n",
    "\n",
    "    return trips\n",
    "\n",
    "\n",
    "def read_accidents(path, box, scale=1000.0):\n",
    "    index_columns = ['i', 'j', 'weekday', 'hour']    \n",
    "    df = pandas.read_csv(path)\n",
    "    df.rename(columns={'day_type': 'weekday', 'time_range': 'hour'}, inplace=True)\n",
    "    df['i'] = ((df['latitude'] - box['lat_min']) * scale).round()\n",
    "    df['j'] = ((df['longitude'] - box['lon_min']) * scale).round()\n",
    "    s = df.groupby(index_columns).apply(len)\n",
    "    accidents = pandas.DataFrame({'accidents': s})\n",
    "    return accidents\n",
    "\n",
    "\n",
    "def make_city_frame(city, \n",
    "                    loc='frosty', \n",
    "                    boxesloc='frosty',\n",
    "                    storeloc='frosty',\n",
    "                    scale=1000.0, \n",
    "                    break_at=None):\n",
    "    \"\"\"\n",
    "    Reads data of trips and accidents and store data frame into HDF format\n",
    "    \"\"\"\n",
    "    paths = getpaths(city, loc=location, boxesloc=boxesloc, storeloc=storeloc)\n",
    "    box = getbox(paths['boxes'], city)\n",
    "    logger.info(\"Reading trips...\")\n",
    "    trips = read_trips(paths['trips'], box, scale=scale, break_at=break_at)\n",
    "    logger.info(\"Reading accidents...\")\n",
    "    accidents = read_accidents(paths['accidents'], box, scale=scale)\n",
    "    logger.info(\"Storing data...\")\n",
    "    joined_df = trips.join(accidents).fillna(0).reset_index()\n",
    "    joined_df.to_hdf(paths['store'], city, complib='blosc', complevel=6)\n",
    "    logger.info(\"Data saved to HDF:\".format(paths['store']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cities = ['bari', 'milano', 'napoli', 'palermo', 'roma', 'torino', 'venezia']\n",
    "location = 'gfs'\n",
    "boxes_location = 'data'\n",
    "store_location = 'data'\n",
    "scale = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to remove an existing store file, if needed. (Use `C-M y` to make the cell runnable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "rm -f /u/gciampag/data/tbdc15/trip_accidents_store.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll -h ~/data/tbdc15/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    logging.info(\"City: {}\".format(city))\n",
    "    make_city_frame(city, \n",
    "                    loc=location, \n",
    "                    scale=scale, \n",
    "                    boxesloc=boxes_location,\n",
    "                    storeloc=store_location, \n",
    "                    break_at=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: .1em\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "from pylab import *\n",
    "\n",
    "# scatter plot\n",
    "def scatter_trips_accidents(df, city, use_trips_starts=False):\n",
    "    if use_trips_starts:\n",
    "        xcol = 'trips_start'\n",
    "    else:\n",
    "        xcol = 'trips'\n",
    "            \n",
    "    df.plot(x=xcol, y='accidents', kind='scatter', marker='x', alpha=.2, color='k')\n",
    "\n",
    "    # trend line\n",
    "    xmin = max(df[xcol].min(), 1)\n",
    "    xmax = df[xcol].max()\n",
    "    bins = numpy.logspace(numpy.log10(xmin), numpy.log10(xmax), 20)\n",
    "    df.groupby(numpy.digitize(df[xcol], bins=bins)).mean().plot(x=xcol, y='accidents',\n",
    "                                                                color='r', linestyle='solid',\n",
    "                                                                marker='o', ax=gca(), alpha=.5, \n",
    "                                                                linewidth=2)\n",
    "    grid('off')\n",
    "    title(city)\n",
    "    if use_trips_starts:\n",
    "        xlabel('Traffic (start of trip)')\n",
    "    else:\n",
    "        xlabel('Traffic')\n",
    "    ylabel('Accidents')\n",
    "    xscale('log')\n",
    "    tight_layout()\n",
    "    savefig('trips_accidents_scatter_{}.pdf'.format(city))\n",
    "    savefig('trips_accidents_scatter_{}.png'.format(city))\n",
    "\n",
    "\n",
    "def hist_accidents(df, city):\n",
    "    hist(df['accidents'], log=True, bins=60, color='white')\n",
    "    ylim(.1, ylim()[1])\n",
    "    xlabel('Accidents')\n",
    "    ylabel('Frequency')\n",
    "    title(city)\n",
    "    tight_layout()\n",
    "    savefig('accidents_histogram_{}.pdf'.format(city))\n",
    "    savefig('accidents_histogram_{}.png'.format(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    paths = getpaths(city, \n",
    "                     loc=location, \n",
    "                     boxesloc=boxes_location,\n",
    "                     storeloc=store_location)\n",
    "    df = pandas.read_hdf(paths['store'], city)\n",
    "    df = df.groupby(['i', 'j']).sum().filter(['trips', 'trips_start', 'accidents'])\n",
    "    scatter_trips_accidents(df, city)\n",
    "    scatter_trips_accidents(df, city, use_trips_starts=True)\n",
    "    hist_accidents(df, city)\n",
    "    print city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot of trips vs trip starts "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df.plot(x='trips_start', y='trips', kind='scatter', alpha=.2, marker='.')\n",
    "xscale('log')\n",
    "yscale('log')\n",
    "xlim(5e-1, 1e5)\n",
    "xlabel('Trip starts')\n",
    "ylabel('Trips')\n",
    "title(city)\n",
    "savefig(\"trips_trips_starts_scatter_{}_{}.pdf\".format(city, scale))\n",
    "savefig(\"trips_trips_starts_scatter_{}_{}.png\".format(city, scale))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

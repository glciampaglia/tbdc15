{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import tarfile\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers[0].setFormatter(logging.Formatter('%(asctime)s: %(message)s'))\n",
    "\n",
    "locations = {\n",
    "    'gfs': '/l/cnets/datasets/Telecom_BDC_2015',\n",
    "    'diskstation': '/media/diskstation/Datasets/Telecom Big Data Challenge 2015',\n",
    "    'data': os.path.expanduser('~/data/tbdc15'),\n",
    "    'hdd': '/media/giovanni/Multimedia/Datasets/Telecom Big Data Challenge 2015',\n",
    "    'repo': os.path.expanduser('~/repos/tbdc15')\n",
    "}\n",
    "\n",
    "\n",
    "def getpaths(city, loc='gfs', boxesloc=None, storeloc=None):\n",
    "    root = locations[loc]\n",
    "    city_codes = {'RO': 'RM'}\n",
    "    code = city[:2].upper()\n",
    "    if code in city_codes:\n",
    "        code = city_codes[code]\n",
    "    paths = {\n",
    "        'trips': '{root}/infoblu/{city}.tar.gz'.format(root=root, city=city),\n",
    "        'accidents': '{root}/unipol/BDC2015_UnipolsaiClaims2014_{city}.csv'.format(root=root, city=code),\n",
    "        'boxes': '{root}/city_boxes.csv'.format(root=root if boxesloc is None else locations[boxesloc]),\n",
    "        'store': '{root}/trip_accidents_store.hdf'.format(root=root if storeloc is None else locations[storeloc])\n",
    "    }\n",
    "    return paths\n",
    "\n",
    "\n",
    "def getbox(path, city):\n",
    "    city_code = city[0].lower()\n",
    "    df_box = pandas.read_csv(path, index_col='city')\n",
    "    df_box.ix[city_code]\n",
    "    box = df_box.ix[city_code].to_dict()\n",
    "    return box\n",
    "\n",
    "\n",
    "def read_trips(path, box, scale=1000.0, break_at=None):\n",
    "    index_columns = ['i', 'j', 'weekday', 'hour']\n",
    "    trips = pandas.DataFrame(columns=index_columns + ['trips', 'trips_start']).set_index(index_columns)\n",
    "\n",
    "    # set break_at to an integer and it will stop exactly after that number of iterations\n",
    "    i = 0\n",
    "\n",
    "    with tarfile.open(path, mode='r:gz') as tf:\n",
    "        # open tar file in random access mode with on-the-fly gzip decompression\n",
    "        for member in tf:\n",
    "            if break_at is not None and i == break_at:\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "            # read contents of TAR archive. Each file in the archive contains \n",
    "            # the data of a different day.\n",
    "            logger.info(member.name)\n",
    "            f = tf.extractfile(member)\n",
    "\n",
    "            # do not use the \"type\" and \"speed\" columns, since we don't need them. This saves memory.\n",
    "            df = pandas.read_csv(f, \n",
    "                                 names=['trip', 'timestamp', 'lat', 'lon', 'type', 'speed'],\n",
    "                                 usecols=['trip', 'timestamp', 'lat', 'lon'],\n",
    "                                 sep=';', \n",
    "                                 parse_dates=['timestamp'])\n",
    "\n",
    "            # compute the cell, weekday, and hour\n",
    "            df['i'] = ((df['lat'] - box['lat_min']) * scale).round()\n",
    "            df['j'] = ((df['lon'] - box['lon_min']) * scale).round()\n",
    "            df['weekday'] = df['timestamp'].map(pandas.Timestamp.weekday)\n",
    "            df['hour'] = df['timestamp'].map(lambda k: k.hour)\n",
    "\n",
    "            # count how many trips in each cell, weekday, hour and append. \n",
    "            # Note that the first group-by returns a series object, \n",
    "            # and we wrap this into a DataFrame.        \n",
    "            s1 = df.filter(index_columns).groupby(index_columns).apply(len)\n",
    "\n",
    "            # do the same but only considering the first frame of each trip.\n",
    "            df_ff = df.groupby('trip', as_index=False).head(1)\n",
    "            s2 = df_ff.filter(index_columns).groupby(index_columns).apply(len)\n",
    "\n",
    "            df = pandas.DataFrame({'trips': s1, 'trips_start': s2})\n",
    "            \n",
    "            trips = trips.append(df)\n",
    "\n",
    "    return trips\n",
    "\n",
    "\n",
    "def read_accidents(path, box, scale=1000.0):\n",
    "    index_columns = ['i', 'j', 'weekday', 'hour']    \n",
    "    df = pandas.read_csv(path)\n",
    "    df.rename(columns={'day_type': 'weekday', 'time_range': 'hour'}, inplace=True)\n",
    "    df['i'] = ((df['latitude'] - box['lat_min']) * scale).round()\n",
    "    df['j'] = ((df['longitude'] - box['lon_min']) * scale).round()\n",
    "    s = df.groupby(index_columns).apply(len)\n",
    "    accidents = pandas.DataFrame({'accidents': s})\n",
    "    return accidents\n",
    "\n",
    "\n",
    "def make_city_frame(city, \n",
    "                    loc='frosty', \n",
    "                    boxesloc='frosty',\n",
    "                    storeloc='frosty',\n",
    "                    scale=1000.0, \n",
    "                    break_at=None):\n",
    "    \"\"\"\n",
    "    Reads data of trips and accidents and store data frame into HDF format\n",
    "    \"\"\"\n",
    "    paths = getpaths(city, loc=location, boxesloc=boxesloc, storeloc=storeloc)\n",
    "    box = getbox(paths['boxes'], city)\n",
    "    logger.info(\"Reading trips...\")\n",
    "    trips = read_trips(paths['trips'], box, scale=scale, break_at=break_at)\n",
    "    logger.info(\"Reading accidents...\")\n",
    "    accidents = read_accidents(paths['accidents'], box, scale=scale)\n",
    "    logger.info(\"Storing data...\")\n",
    "    joined_df = trips.join(accidents).fillna(0).reset_index()\n",
    "    joined_df.to_hdf(paths['store'], city, complib='blosc', complevel=6)\n",
    "    logger.info(\"Data saved to HDF:\".format(paths['store']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select city "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cities = ['bari', 'milano', 'napoli', 'palermo', 'roma', 'torino', 'venezia']\n",
    "location = 'gfs'\n",
    "boxes_location = 'data'\n",
    "store_location = 'data'\n",
    "scale = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to remove an existing store file, if needed. (Use `C-M y` to make the cell runnable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "rm -f /u/gciampag/data/tbdc15/trip_accidents_store.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll -h ~/data/tbdc15/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for city in cities:\n",
    "    logging.info(\"City: {}\".format(city))\n",
    "    make_city_frame(city, \n",
    "                    loc=location, \n",
    "                    scale=scale, \n",
    "                    boxesloc=boxes_location,\n",
    "                    storeloc=store_location, \n",
    "                    break_at=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: .1em\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "from pylab import *\n",
    "\n",
    "# scatter plot\n",
    "def scatter_trips_accidents(df, city, use_trips_starts=False):\n",
    "    fig = figure()\n",
    "    if use_trips_starts:\n",
    "        xcol = 'trips_start'\n",
    "    else:\n",
    "        xcol = 'trips'\n",
    "            \n",
    "    df.plot(x=xcol, y='accidents', kind='scatter', marker='x', alpha=.2, color='k', fig=fig)\n",
    "\n",
    "    # trend line\n",
    "    emin = numpy.log10(df[xcol].min())\n",
    "    emax = numpy.log10(df[xcol].max())\n",
    "    bins = numpy.logspace(max(emin, 0), emax, 20)\n",
    "    print bins\n",
    "    df.groupby(numpy.digitize(df[xcol], bins=bins)).mean().plot(x=xcol, y='accidents',\n",
    "                                                                color='r', linestyle='solid',\n",
    "                                                                marker='o', ax=gca(), alpha=.5, \n",
    "                                                                linewidth=2, fig=fig)\n",
    "    grid('off')\n",
    "    title(city)\n",
    "    if use_trips_starts:\n",
    "        xlabel('Traffic (start of trip)')\n",
    "    else:\n",
    "        xlabel('Traffic')\n",
    "    ylabel('Accidents')\n",
    "    xscale('log')\n",
    "    xlim(1, xlim()[1])\n",
    "    tight_layout()\n",
    "    legend()\n",
    "    savefig('trips_accidents_scatter_{}.pdf'.format(city))\n",
    "    savefig('trips_accidents_scatter_{}.png'.format(city))\n",
    "    show()\n",
    "\n",
    "\n",
    "def hist_accidents(df, city):\n",
    "    fig = figure()\n",
    "    ax = gca()\n",
    "    ax.hist(df['accidents'].values, log=True, bins=60, color='white')\n",
    "    ylim(.1, ylim()[1])\n",
    "    xlabel('Accidents')\n",
    "    ylabel('Frequency')\n",
    "    title(city)\n",
    "    tight_layout()\n",
    "    legend()\n",
    "    savefig('accidents_histogram_{}.pdf'.format(city))\n",
    "    savefig('accidents_histogram_{}.png'.format(city))\n",
    "    show()\n",
    "    \n",
    "    \n",
    "def plot_all(city):\n",
    "    paths = getpaths(city, \n",
    "                     loc=location, \n",
    "                     boxesloc=boxes_location,\n",
    "                     storeloc=store_location)\n",
    "    df = pandas.read_hdf(paths['store'], city)\n",
    "    df = df.groupby(['i', 'j']).sum().filter(['trips', 'trips_start', 'accidents'])\n",
    "    scatter_trips_accidents(df, city)\n",
    "    scatter_trips_accidents(df, city, use_trips_starts=True)\n",
    "    hist_accidents(df, city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_all('bari')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all('milano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all('napoli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all('palermo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all('roma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all('torino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_all('venezia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot of trips vs trip starts "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df.plot(x='trips_start', y='trips', kind='scatter', alpha=.2, marker='.')\n",
    "xscale('log')\n",
    "yscale('log')\n",
    "xlim(5e-1, 1e5)\n",
    "xlabel('Trip starts')\n",
    "ylabel('Trips')\n",
    "title(city)\n",
    "savefig(\"trips_trips_starts_scatter_{}_{}.pdf\".format(city, scale))\n",
    "savefig(\"trips_trips_starts_scatter_{}_{}.png\".format(city, scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of accidents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "city = 'palermo'\n",
    "df = pandas.read_hdf('/u/gciampag/data/tbdc15/trip_accidents_store.hdf', city)\n",
    "df = df.groupby(['i', 'j']).sum().filter(['trips', 'trips_start', 'accidents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram grouping data $>0$ in bins of size $9$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_size = 9  # lower bound on bin size\n",
    "max_accidents = df['accidents'].max()\n",
    "start = 1\n",
    "stop = 1 + ceil((max_accidents - 1) / bin_size) * bin_size\n",
    "num = (stop - start) / bin_size + 1\n",
    "bins = numpy.linspace(start, stop, num, endpoint=True)\n",
    "bins = numpy.hstack([[0,], bins])\n",
    "nh, __, ___ = hist(df['accidents'].values, bins=bins, color='lightgray', log=True, normed=True, histtype='bar')\n",
    "xlim(-5, stop)\n",
    "ylim(1e-7, 1)\n",
    "xlabel('Accidents')\n",
    "ylabel('Frequency')\n",
    "title(city.title())\n",
    "tick_params(axis='both', direction='out', which='both')\n",
    "tick_params(axis='x', which='minor', bottom='on', top='off')\n",
    "tick_params(axis='y', which='both', right='off')\n",
    "tick_params(axis='x', which='major', top='off')\n",
    "tick_params(axis='x', which='minor', bottom='on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the $>0$ data with an exponential law (with binning), and geometric distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import expon, geom, poisson\n",
    "\n",
    "group_size = 9\n",
    "\n",
    "df_nza = df.query('accidents > 0')\n",
    "a = df_nza.groupby(ceil(df_nza['accidents'] / group_size)).count()['accidents']\n",
    "\n",
    "x = a.index.values\n",
    "\n",
    "p = a / a.sum()\n",
    "vlines(x, 0, p, color='LightGray')\n",
    "plot(x, p, 'wo ', label='Data', ms=8)\n",
    "\n",
    "# expected number of accidents (computed as a weighted average of the frequencies)\n",
    "exp_accidents = np.sum(p.values * a.index.values)\n",
    "\n",
    "#x = np.hstack([[0]])\n",
    "\n",
    "rv = expon(loc=0, scale=exp_accidents ** -1)\n",
    "plot(x, rv.cdf(x + 1) - rv.cdf(x), 'x ', color='k', mew=2, label='Exponential')\n",
    "\n",
    "rv = geom(exp_accidents ** -1, loc=0)\n",
    "plot(x, rv.pmf(x), '+ ', color='gray', mew=1.5, ms=10, label='Geometric')\n",
    "\n",
    "rv = poisson(exp_accidents ** -1, loc=0)\n",
    "plot(x, rv.pmf(x), marker=(6, 2, 0), ls=' ', color='LightGray', mew=1, ms=10, label='Poisson')\n",
    "\n",
    "\n",
    "xlim(0, xlim()[1] + 1)\n",
    "xlabel(r'$\\left\\lceil\\rm{Accidents} \\,/\\, %d\\right\\rceil$' % group_size, fontsize='large')\n",
    "ylabel('Probability')\n",
    "yscale('log')\n",
    "ylim(ylim()[0], 2)\n",
    "title(city.title())\n",
    "legend(loc='best', frameon=False)\n",
    "tick_params(axis='both', direction='out', which='both')\n",
    "tick_params(axis='x', which='minor', bottom='on', top='off')\n",
    "tick_params(axis='y', which='both', right='off')\n",
    "tick_params(axis='x', which='major', top='off')\n",
    "tick_params(axis='x', which='minor', bottom='on')\n",
    "savefig(\"accidents_grouped_fit_{}.png\".format(city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-inflated geometric distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.stats import rv_discrete\n",
    "\n",
    "class zigeom_gen(rv_discrete):\n",
    "    def _pmf(self, k, pi, p):\n",
    "        s = numpy.sign(k)\n",
    "        return (1 - s) * (pi + (1.0 - pi) * p) + s * (1.0 - pi) * (1.0 - p) ** k * p\n",
    "            \n",
    "zigeom = zigeom_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate from a zero-inflated geometric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def fit(data):\n",
    "    def _llk(args):\n",
    "        return - zigeom(*args).logpmf(data).sum()\n",
    "    N = float(len(data))\n",
    "    pi0 = (data == 0).sum() / N\n",
    "    x0 = (pi0, .5)\n",
    "    ret = minimize(_llk, x0, method='Nelder-Mead')\n",
    "    if ret['success']:\n",
    "        return ret['x']\n",
    "    else:\n",
    "        raise RuntimeError(ret['message'])\n",
    "\n",
    "pi = .2\n",
    "p = .3\n",
    "data = zigeom(pi, p).rvs(size=1000)\n",
    "print fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "pi = 0.5\n",
    "data = zigeom(pi, p).rvs(size=2000)\n",
    "data_max = data.max()\n",
    "hist(data, bins=data_max, color='white', log=True, normed=True)\n",
    "pih, ph = fit(data)\n",
    "x = np.arange(data_max)\n",
    "px = zigeom(pih, ph).pmf(x)\n",
    "plot(x + .5, px, 'r-')\n",
    "title('$\\pi = {}, p = {}$'.format(pi, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the trip distribution for cells with $0$ accidents with a normal cell (with $\\ge 0$ accidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from truthy_measure.plotting import plot_pdf_log2, plot_cdf\n",
    "\n",
    "trips_all = df['trips'].values\n",
    "trips_zac = df.query('accidents == 0')['trips'].values\n",
    "num_points = 20\n",
    "bins = numpy.logspace(0, numpy.log2(trips_all.max()), num=num_points, base=2)\n",
    "hist_all, __ = numpy.histogram(trips_all, bins=bins, normed=True)\n",
    "hist_zac, __ = numpy.histogram(trips_zac, bins=bins, normed=True)\n",
    "plot(bins[1:], numpy.log(hist_zac) - numpy.log(hist_all), 'ko:', mfc='LightGray')\n",
    "axhline(0, ls='--', color='gray', lw=2)\n",
    "xscale('log')\n",
    "xlabel('Trips $t$')\n",
    "ylabel('$\\log\\Pr\\{T = t | A = 0\\} - \\log\\Pr\\{T\\}$')\n",
    "yb = max(numpy.abs(ylim()))\n",
    "ylim(-yb, yb)\n",
    "title(city.title())\n",
    "tight_layout()\n",
    "savefig(\"logratio_{}.png\".format(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
